{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60659737",
   "metadata": {
    "papermill": {
     "duration": 0.013361,
     "end_time": "2024-03-26T09:33:13.099239",
     "exception": false,
     "start_time": "2024-03-26T09:33:13.085878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Notebook 4: K Nearest Neighbours using Euclidian Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e07b1f",
   "metadata": {
    "papermill": {
     "duration": 0.012123,
     "end_time": "2024-03-26T09:33:13.124979",
     "exception": false,
     "start_time": "2024-03-26T09:33:13.112856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Little Introduction before we go on. Myself Pathik Viramgama (Pr0fess0r) and am doing a 75 days kaggle challenge where I will try rise up to as much high in rank as possible in a total of 300 hours (4 hours per day). So upvote! What we are going to do here is to see what is the mathematical aspect that goes behind in K nearest neighbour. This is the **fourth** notebook in the series of scratch coding. We will progress in the difficulty as we go ahead and will surely cover all the basic ML codes from scratch to the deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d98fa0",
   "metadata": {
    "papermill": {
     "duration": 0.012045,
     "end_time": "2024-03-26T09:33:13.149998",
     "exception": false,
     "start_time": "2024-03-26T09:33:13.137953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Dataset \n",
    "### and Legen......wait for it......dary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23e3e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:13.177271Z",
     "iopub.status.busy": "2024-03-26T09:33:13.176580Z",
     "iopub.status.idle": "2024-03-26T09:33:14.163749Z",
     "shell.execute_reply": "2024-03-26T09:33:14.162556Z"
    },
    "papermill": {
     "duration": 1.004586,
     "end_time": "2024-03-26T09:33:14.166990",
     "exception": false,
     "start_time": "2024-03-26T09:33:13.162404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bec21",
   "metadata": {
    "papermill": {
     "duration": 0.012388,
     "end_time": "2024-03-26T09:33:14.192064",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.179676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is also a classification algorithm. This is a simple two Category classfication with the Banana Dataset, which basically has some feature values for banana and based on that we need to predict if the banana is good or not. So lets begin with tampering with the data so that our model can read it and learn from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7b510b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:14.218944Z",
     "iopub.status.busy": "2024-03-26T09:33:14.218378Z",
     "iopub.status.idle": "2024-03-26T09:33:14.292174Z",
     "shell.execute_reply": "2024-03-26T09:33:14.291387Z"
    },
    "papermill": {
     "duration": 0.09051,
     "end_time": "2024-03-26T09:33:14.295186",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.204676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Softness</th>\n",
       "      <th>HarvestTime</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.924968</td>\n",
       "      <td>0.468078</td>\n",
       "      <td>3.077832</td>\n",
       "      <td>-1.472177</td>\n",
       "      <td>0.294799</td>\n",
       "      <td>2.435570</td>\n",
       "      <td>0.271290</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.409751</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.346921</td>\n",
       "      <td>-2.495099</td>\n",
       "      <td>-0.892213</td>\n",
       "      <td>2.067549</td>\n",
       "      <td>0.307325</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.357607</td>\n",
       "      <td>1.483176</td>\n",
       "      <td>1.568452</td>\n",
       "      <td>-2.645145</td>\n",
       "      <td>-0.647267</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>1.427322</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.868524</td>\n",
       "      <td>1.566201</td>\n",
       "      <td>1.889605</td>\n",
       "      <td>-1.273761</td>\n",
       "      <td>-1.006278</td>\n",
       "      <td>1.873001</td>\n",
       "      <td>0.477862</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.651825</td>\n",
       "      <td>1.319199</td>\n",
       "      <td>-0.022459</td>\n",
       "      <td>-1.209709</td>\n",
       "      <td>-1.430692</td>\n",
       "      <td>1.078345</td>\n",
       "      <td>2.812442</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-6.414403</td>\n",
       "      <td>0.723565</td>\n",
       "      <td>1.134953</td>\n",
       "      <td>2.952763</td>\n",
       "      <td>0.297928</td>\n",
       "      <td>-0.156946</td>\n",
       "      <td>2.398091</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.851143</td>\n",
       "      <td>-2.217875</td>\n",
       "      <td>-2.812175</td>\n",
       "      <td>0.489249</td>\n",
       "      <td>-1.323410</td>\n",
       "      <td>-2.316883</td>\n",
       "      <td>2.113136</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1.422722</td>\n",
       "      <td>-1.907665</td>\n",
       "      <td>-2.532364</td>\n",
       "      <td>0.964976</td>\n",
       "      <td>-0.562375</td>\n",
       "      <td>-1.834765</td>\n",
       "      <td>0.697361</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-2.131904</td>\n",
       "      <td>-2.742600</td>\n",
       "      <td>-1.008029</td>\n",
       "      <td>2.126946</td>\n",
       "      <td>-0.802632</td>\n",
       "      <td>-3.580266</td>\n",
       "      <td>0.423569</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-2.660879</td>\n",
       "      <td>-2.044666</td>\n",
       "      <td>0.159026</td>\n",
       "      <td>1.499706</td>\n",
       "      <td>-1.581856</td>\n",
       "      <td>-1.605859</td>\n",
       "      <td>1.435644</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness  \\\n",
       "0    -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570   \n",
       "1    -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549   \n",
       "2    -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643   \n",
       "3    -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001   \n",
       "4     0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345   \n",
       "...        ...       ...        ...       ...          ...       ...   \n",
       "7995 -6.414403  0.723565   1.134953  2.952763     0.297928 -0.156946   \n",
       "7996  0.851143 -2.217875  -2.812175  0.489249    -1.323410 -2.316883   \n",
       "7997  1.422722 -1.907665  -2.532364  0.964976    -0.562375 -1.834765   \n",
       "7998 -2.131904 -2.742600  -1.008029  2.126946    -0.802632 -3.580266   \n",
       "7999 -2.660879 -2.044666   0.159026  1.499706    -1.581856 -1.605859   \n",
       "\n",
       "       Acidity Quality  \n",
       "0     0.271290    Good  \n",
       "1     0.307325    Good  \n",
       "2     1.427322    Good  \n",
       "3     0.477862    Good  \n",
       "4     2.812442    Good  \n",
       "...        ...     ...  \n",
       "7995  2.398091     Bad  \n",
       "7996  2.113136     Bad  \n",
       "7997  0.697361     Bad  \n",
       "7998  0.423569     Bad  \n",
       "7999  1.435644     Bad  \n",
       "\n",
       "[8000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data\\banana_quality_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8809799c",
   "metadata": {
    "papermill": {
     "duration": 0.012295,
     "end_time": "2024-03-26T09:33:14.320178",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.307883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4617b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:14.347573Z",
     "iopub.status.busy": "2024-03-26T09:33:14.346872Z",
     "iopub.status.idle": "2024-03-26T09:33:14.358171Z",
     "shell.execute_reply": "2024-03-26T09:33:14.357025Z"
    },
    "papermill": {
     "duration": 0.028143,
     "end_time": "2024-03-26T09:33:14.360937",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.332794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df.drop(['Quality'], axis = 1)\n",
    "y = df['Quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d816af",
   "metadata": {
    "papermill": {
     "duration": 0.012226,
     "end_time": "2024-03-26T09:33:14.386041",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.373815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now as I said before, machine learning does not speak English, Spanish, French or basically any typical language of communication. It only understands numbers, and that too logical numbers. If you would have noticed we have textual data in our dataset. We need to make them into numbers. But how would you convert text into numbers while preserving the meaning of text? No not morse code idiots, we are not in 1920. Think! Think Hard!\n",
    "\n",
    "\"We do not have have all day\"-Viru Sahastra Buddhe\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "(Still Waiting)\n",
    "\n",
    "...\n",
    "\n",
    "(Waiting faster now)\n",
    "\n",
    "...\n",
    "\n",
    "Ahh nevermind. I am going to spill the beans. **For every different text in each feature, we assign a unique number.** This will be a good time to make you learn how to write and read psuedo code. Here is a formal way of writing what is there in **bold** text.\n",
    "\n",
    "(Latex Code)\n",
    "\n",
    "Now let me explain this in english with an example (with a controversial feature). Say I have a single feature \"Sex\". It will have three types of entries in it. One is the \"male\", second \"female\" and third \"LGBTQ+\". I will assign the number \"0\" to \"male\", number \"1\" to \"female\" and \"2\" to \"LGBTQ+\". I will now replace the textual data in \"Sex\" column with the numbers I just assigned. Voila! This is called Label Encoding.\n",
    "\n",
    "Generally for features, what we use is One Hot Encoding and for target we use Label Encoding. We will be using Label Encoding for everything here to keep it simple. I used a library here but you can see the scratch implementaion [here](https://www.kaggle.com/pathikviramgama/code) in my profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7cbbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:14.413630Z",
     "iopub.status.busy": "2024-03-26T09:33:14.413171Z",
     "iopub.status.idle": "2024-03-26T09:33:15.780903Z",
     "shell.execute_reply": "2024-03-26T09:33:15.779730Z"
    },
    "papermill": {
     "duration": 1.384503,
     "end_time": "2024-03-26T09:33:15.783634",
     "exception": false,
     "start_time": "2024-03-26T09:33:14.399131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc3e1c",
   "metadata": {
    "papermill": {
     "duration": 0.012268,
     "end_time": "2024-03-26T09:33:15.808848",
     "exception": false,
     "start_time": "2024-03-26T09:33:15.796580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yeah I know I am cheating, using a library. But hear me out please. This notebook needs you to focus on how the KNN works with Euclidian Distance, not how split occurs. But I have created that pre processing stuff from scratch in another notebook. You can check that out in my profile [here](https://www.kaggle.com/pathikviramgama/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfc92a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:15.836287Z",
     "iopub.status.busy": "2024-03-26T09:33:15.835875Z",
     "iopub.status.idle": "2024-03-26T09:33:15.970046Z",
     "shell.execute_reply": "2024-03-26T09:33:15.968725Z"
    },
    "papermill": {
     "duration": 0.151549,
     "end_time": "2024-03-26T09:33:15.973495",
     "exception": false,
     "start_time": "2024-03-26T09:33:15.821946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c8337f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.001229Z",
     "iopub.status.busy": "2024-03-26T09:33:16.000753Z",
     "iopub.status.idle": "2024-03-26T09:33:16.020733Z",
     "shell.execute_reply": "2024-03-26T09:33:16.019589Z"
    },
    "papermill": {
     "duration": 0.036867,
     "end_time": "2024-03-26T09:33:16.023109",
     "exception": false,
     "start_time": "2024-03-26T09:33:15.986242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Softness</th>\n",
       "      <th>HarvestTime</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>-2.985174</td>\n",
       "      <td>-0.308381</td>\n",
       "      <td>-2.537152</td>\n",
       "      <td>1.206068</td>\n",
       "      <td>-1.903491</td>\n",
       "      <td>-1.380864</td>\n",
       "      <td>4.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>-0.947581</td>\n",
       "      <td>-1.411094</td>\n",
       "      <td>-2.526169</td>\n",
       "      <td>1.484966</td>\n",
       "      <td>3.095214</td>\n",
       "      <td>1.434772</td>\n",
       "      <td>-0.554518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>0.562389</td>\n",
       "      <td>-2.701049</td>\n",
       "      <td>-1.630511</td>\n",
       "      <td>-4.598747</td>\n",
       "      <td>-0.126164</td>\n",
       "      <td>1.072228</td>\n",
       "      <td>0.497335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>-0.930195</td>\n",
       "      <td>-3.864073</td>\n",
       "      <td>-0.164199</td>\n",
       "      <td>1.748238</td>\n",
       "      <td>1.620881</td>\n",
       "      <td>2.927055</td>\n",
       "      <td>-4.292252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>0.969861</td>\n",
       "      <td>-1.580322</td>\n",
       "      <td>-2.375037</td>\n",
       "      <td>-1.472371</td>\n",
       "      <td>-0.039946</td>\n",
       "      <td>3.886455</td>\n",
       "      <td>-2.455290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0.323835</td>\n",
       "      <td>-2.695930</td>\n",
       "      <td>-0.175959</td>\n",
       "      <td>0.290220</td>\n",
       "      <td>1.321225</td>\n",
       "      <td>1.777267</td>\n",
       "      <td>-3.199724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.015700</td>\n",
       "      <td>-0.558582</td>\n",
       "      <td>-1.833480</td>\n",
       "      <td>2.862550</td>\n",
       "      <td>3.056284</td>\n",
       "      <td>-0.033990</td>\n",
       "      <td>0.540286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-2.327883</td>\n",
       "      <td>1.462492</td>\n",
       "      <td>2.726482</td>\n",
       "      <td>-0.946511</td>\n",
       "      <td>-2.493530</td>\n",
       "      <td>0.416074</td>\n",
       "      <td>0.647311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>1.266055</td>\n",
       "      <td>-1.480548</td>\n",
       "      <td>-4.757917</td>\n",
       "      <td>0.352227</td>\n",
       "      <td>-0.820586</td>\n",
       "      <td>-1.837556</td>\n",
       "      <td>3.323480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>-1.368017</td>\n",
       "      <td>-6.185589</td>\n",
       "      <td>-3.241598</td>\n",
       "      <td>1.597930</td>\n",
       "      <td>-3.335859</td>\n",
       "      <td>-1.328053</td>\n",
       "      <td>-1.601291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Size    Weight  Sweetness  Softness  HarvestTime  Ripeness   Acidity\n",
       "7935 -2.985174 -0.308381  -2.537152  1.206068    -1.903491 -1.380864  4.003589\n",
       "4608 -0.947581 -1.411094  -2.526169  1.484966     3.095214  1.434772 -0.554518\n",
       "2939  0.562389 -2.701049  -1.630511 -4.598747    -0.126164  1.072228  0.497335\n",
       "4336 -0.930195 -3.864073  -0.164199  1.748238     1.620881  2.927055 -4.292252\n",
       "3658  0.969861 -1.580322  -2.375037 -1.472371    -0.039946  3.886455 -2.455290\n",
       "...        ...       ...        ...       ...          ...       ...       ...\n",
       "5226  0.323835 -2.695930  -0.175959  0.290220     1.321225  1.777267 -3.199724\n",
       "5390  1.015700 -0.558582  -1.833480  2.862550     3.056284 -0.033990  0.540286\n",
       "860  -2.327883  1.462492   2.726482 -0.946511    -2.493530  0.416074  0.647311\n",
       "7603  1.266055 -1.480548  -4.757917  0.352227    -0.820586 -1.837556  3.323480\n",
       "7270 -1.368017 -6.185589  -3.241598  1.597930    -3.335859 -1.328053 -1.601291\n",
       "\n",
       "[7200 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e59c88",
   "metadata": {
    "papermill": {
     "duration": 0.012653,
     "end_time": "2024-03-26T09:33:16.048915",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.036262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KNN with Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7200ce1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.076634Z",
     "iopub.status.busy": "2024-03-26T09:33:16.076181Z",
     "iopub.status.idle": "2024-03-26T09:33:16.421583Z",
     "shell.execute_reply": "2024-03-26T09:33:16.420198Z"
    },
    "papermill": {
     "duration": 0.362287,
     "end_time": "2024-03-26T09:33:16.424215",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.061928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "KNN.fit(x_train, y_train)\n",
    "\n",
    "KNN.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31c98e",
   "metadata": {
    "papermill": {
     "duration": 0.013364,
     "end_time": "2024-03-26T09:33:16.450826",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.437462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below are the different distance formula that the library offers. There are also algorithms inside this algorithm that can be used like KD Tree and Ball Tree. We dont need to mess with those algorithms right now, consider them useless right now. But I do need to tell you about the distances. Based on your nature of data, you will have different accuracies for different distance formulas used. \"Its all uncle Ned up there\"- Mind your language. Just wanted you to see this. We won't be needing this further up this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2eb9bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.479027Z",
     "iopub.status.busy": "2024-03-26T09:33:16.478623Z",
     "iopub.status.idle": "2024-03-26T09:33:16.485783Z",
     "shell.execute_reply": "2024-03-26T09:33:16.484699Z"
    },
    "papermill": {
     "duration": 0.024363,
     "end_time": "2024-03-26T09:33:16.488550",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.464187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cityblock', 'cosine', 'euclidean', 'haversine', 'l2', 'l1', 'manhattan', 'precomputed', 'nan_euclidean'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of available metrics for the classifier\n",
    "from sklearn.metrics import pairwise\n",
    "pairwise.distance_metrics().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eecc8f",
   "metadata": {
    "papermill": {
     "duration": 0.013177,
     "end_time": "2024-03-26T09:33:16.515023",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.501846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0af990",
   "metadata": {
    "papermill": {
     "duration": 0.012808,
     "end_time": "2024-03-26T09:33:16.541168",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.528360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "KNN is a very simple algorithm and it uses distance measuring for calculating the answer. If there was a word to describe something that is more simple than the word 'simple', I would use it to describe KNN. Here let me explain with an example. You are at your home. You want to eat food as soon as possible. You don't care about the taste of food. You searched on maps and found Chipotle will be the nearest and quickest place to go. You went. The task of finding what's nearest, that is KNN for a single class.\n",
    "\n",
    "Now if you need a specific taste that is also possible. Say you want tacos only from all the food varities avaialabe in this world. So you search nearest Taco places instead of food places. This is a part KNN as we use in code. \n",
    "\n",
    "I lied. That is not exactly what we do. In essence, we are selecting those features who have similarity to our example input and checking which class it relates more to, and assign that class to our example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff7b3f",
   "metadata": {
    "papermill": {
     "duration": 0.013197,
     "end_time": "2024-03-26T09:33:16.627358",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.614161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So here is a clear outline of what we will do.\n",
    "1. We find distance between our test example and all the train examples using some distance formula.\n",
    "2. We select 'k' nearest examples from test example i.e. select those examples from train that has least distance from test example.\n",
    "3. Check the class for selected examples and whichever class occurs the most number of times in those selected examples, assign that to our test example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2af99",
   "metadata": {
    "papermill": {
     "duration": 0.01307,
     "end_time": "2024-03-26T09:33:16.653959",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.640889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So first we need is a distance calulator. We have dozens of different method of distance calculation. Most used are Manhattan and Euclidian. Sometimes Cosine also works. Lets create functions for that on a general basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa7d0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.683459Z",
     "iopub.status.busy": "2024-03-26T09:33:16.682151Z",
     "iopub.status.idle": "2024-03-26T09:33:16.688921Z",
     "shell.execute_reply": "2024-03-26T09:33:16.688094Z"
    },
    "papermill": {
     "duration": 0.023987,
     "end_time": "2024-03-26T09:33:16.691330",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.667343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidianDistance(x_test_example, x_train_example):\n",
    "    temp = 0\n",
    "    for i in range(len(x_test_example)-1):\n",
    "        temp += (x_test_example[i] - x_train_example[i])**2 \n",
    "        distance = np.sqrt(temp)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26127846",
   "metadata": {
    "papermill": {
     "duration": 0.013211,
     "end_time": "2024-03-26T09:33:16.718280",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.705069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we get the distance from all train data to our input test sample, and select k least distant(nearest neighbor) from them. We do this by root of sum of sqaures of each row. Here is a view for it:\n",
    "\n",
    "$Distance = \\sqrt{(xTrain_1 - xTest_1)^2 + (xTrain_2 - xTest_2)^2+...(xTrain_n - xTest_n)^2}$\n",
    "\n",
    "where $n = $number of columns\n",
    "\n",
    "$xTrain = $single row of train data\n",
    "\n",
    "$xTest = $single row of test data\n",
    "\n",
    "We calcualte distance for all $m$ examples this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df359614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.747761Z",
     "iopub.status.busy": "2024-03-26T09:33:16.746708Z",
     "iopub.status.idle": "2024-03-26T09:33:16.753727Z",
     "shell.execute_reply": "2024-03-26T09:33:16.752774Z"
    },
    "papermill": {
     "duration": 0.024351,
     "end_time": "2024-03-26T09:33:16.756102",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.731751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findNeighbors(x_train, x_test, k):\n",
    "    nearest_index_collection = []\n",
    "    for each_test_row in x_test.values:\n",
    "        d_list = []\n",
    "        for each_train_row in x_train.values:\n",
    "            d_list.append(euclidianDistance(each_test_row, each_train_row))\n",
    "        res = sorted(range(len(d_list)), key=lambda x: d_list[x])[:k]\n",
    "        nearest_index_collection.append(res)\n",
    "    return nearest_index_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979b4f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.785021Z",
     "iopub.status.busy": "2024-03-26T09:33:16.784643Z",
     "iopub.status.idle": "2024-03-26T09:33:16.790321Z",
     "shell.execute_reply": "2024-03-26T09:33:16.789347Z"
    },
    "papermill": {
     "duration": 0.022884,
     "end_time": "2024-03-26T09:33:16.792590",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.769706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attachLabels(nearest_index_collection, x_train):\n",
    "    label_list = []\n",
    "    for each_test_row in nearest_index_collection:\n",
    "        lst = []\n",
    "        for each_train_row_index in each_test_row:\n",
    "            lst.append((each_train_row_index, y_train[each_train_row_index]))\n",
    "        label_list.append(lst)\n",
    "        \n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020d3111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.821319Z",
     "iopub.status.busy": "2024-03-26T09:33:16.820934Z",
     "iopub.status.idle": "2024-03-26T09:33:16.827725Z",
     "shell.execute_reply": "2024-03-26T09:33:16.826676Z"
    },
    "papermill": {
     "duration": 0.024208,
     "end_time": "2024-03-26T09:33:16.830231",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.806023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(label_list):\n",
    "    y_pred = []\n",
    "    for each_test_row in label_list:\n",
    "        y_pred.append(max(set(each_test_row), key = each_test_row.count)[1])\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c9bc1",
   "metadata": {
    "papermill": {
     "duration": 0.014521,
     "end_time": "2024-03-26T09:33:16.858381",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.843860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yup looks easier than Decision Tree. Heck it's the easiest one in all of machine learning. I should have thought sooner about this one. But it will take a lot of time since for each of 800 test sentences, we are doing distance calculation for 7200 train sentences making a total of 5760000 calculations in total! So it is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a081ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:33:16.887888Z",
     "iopub.status.busy": "2024-03-26T09:33:16.887463Z",
     "iopub.status.idle": "2024-03-26T09:34:59.968283Z",
     "shell.execute_reply": "2024-03-26T09:34:59.966931Z"
    },
    "papermill": {
     "duration": 103.113214,
     "end_time": "2024-03-26T09:34:59.985093",
     "exception": false,
     "start_time": "2024-03-26T09:33:16.871879",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3182, 1441, 2026]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_index_collection = findNeighbors(x_train, x_test, 3)\n",
    "nearest_index_collection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6c1bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.014234Z",
     "iopub.status.busy": "2024-03-26T09:35:00.013836Z",
     "iopub.status.idle": "2024-03-26T09:35:00.023877Z",
     "shell.execute_reply": "2024-03-26T09:35:00.022662Z"
    },
    "papermill": {
     "duration": 0.027404,
     "end_time": "2024-03-26T09:35:00.026256",
     "exception": false,
     "start_time": "2024-03-26T09:34:59.998852",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3182, 0), (1441, 0), (2026, 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = attachLabels(nearest_index_collection, x_train)\n",
    "label_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "164a836a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.056341Z",
     "iopub.status.busy": "2024-03-26T09:35:00.055964Z",
     "iopub.status.idle": "2024-03-26T09:35:00.065696Z",
     "shell.execute_reply": "2024-03-26T09:35:00.064533Z"
    },
    "papermill": {
     "duration": 0.027718,
     "end_time": "2024-03-26T09:35:00.068317",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.040599",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(label_list)\n",
    "y_pred = list(y_pred)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77bd35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.098377Z",
     "iopub.status.busy": "2024-03-26T09:35:00.097637Z",
     "iopub.status.idle": "2024-03-26T09:35:00.104997Z",
     "shell.execute_reply": "2024-03-26T09:35:00.103835Z"
    },
    "papermill": {
     "duration": 0.025058,
     "end_time": "2024-03-26T09:35:00.107518",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.082460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = list(y_test)\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66216db6",
   "metadata": {
    "papermill": {
     "duration": 0.013693,
     "end_time": "2024-03-26T09:35:00.135356",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.121663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e658af8",
   "metadata": {
    "papermill": {
     "duration": 0.014318,
     "end_time": "2024-03-26T09:35:00.163735",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.149417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now lets evaluate our algorithm. For classification we have multiple things to rate our model. Unlike Regression, clssificaation has accuracy. But it has a hundered more things. Now just for the purpose of harasing you I will include as many as I can. However please note that you might only need a handful of these, and library functions for each of them is available too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9914d",
   "metadata": {
    "papermill": {
     "duration": 0.013781,
     "end_time": "2024-03-26T09:35:00.192573",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.178792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Basic Evaluation Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224fab7",
   "metadata": {
    "papermill": {
     "duration": 0.01368,
     "end_time": "2024-03-26T09:35:00.220600",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.206920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we will understand how many different answer our model can give.\n",
    "1. Model predicted 0 and in reality it is 0. These predictions are called true negatives.\n",
    "2. Model predicted 0 but in reality it is 1. These predictions are called false negatives\n",
    "3. Model predicted 1 and in reality it is 1. These predictions are called true positives.\n",
    "4. Model predicted 1 but in reality it is 0. These predictions are called false positives.\n",
    "\n",
    "Now since this is scratch coding, we will code this too from scratch. Let's code in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "107049d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.250267Z",
     "iopub.status.busy": "2024-03-26T09:35:00.249863Z",
     "iopub.status.idle": "2024-03-26T09:35:00.259322Z",
     "shell.execute_reply": "2024-03-26T09:35:00.258185Z"
    },
    "papermill": {
     "duration": 0.02697,
     "end_time": "2024-03-26T09:35:00.261609",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.234639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findConfusionTerms(y, y_pred):\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for i in range(len(y_pred)):\n",
    "\n",
    "        if(y_pred[i] == 0 and y[i] == 0):\n",
    "            TN += 1\n",
    "\n",
    "        if(y_pred[i] == 0 and y[i] == 1):\n",
    "            FN += 1\n",
    "\n",
    "        if(y_pred[i] == 1 and y[i] == 1):\n",
    "            TP += 1 \n",
    "\n",
    "        if(y_pred[i] == 1 and y[i] == 0):\n",
    "            FP += 1\n",
    "\n",
    "    return TN, FN, TP, FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bd500",
   "metadata": {
    "papermill": {
     "duration": 0.014058,
     "end_time": "2024-03-26T09:35:00.291828",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.277770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we calculate what is called a confusion matrix! It is basically a visual representaion of these terms in a better way! Now I am no graphic designer so I am just creating a simple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0a31bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.322493Z",
     "iopub.status.busy": "2024-03-26T09:35:00.322091Z",
     "iopub.status.idle": "2024-03-26T09:35:00.327442Z",
     "shell.execute_reply": "2024-03-26T09:35:00.326012Z"
    },
    "papermill": {
     "duration": 0.023326,
     "end_time": "2024-03-26T09:35:00.329724",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.306398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findConfusionMatrix(TN, FN, TP, FP):\n",
    "    CM = [[TN, FP],[FN, TP]]\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fce876",
   "metadata": {
    "papermill": {
     "duration": 0.013591,
     "end_time": "2024-03-26T09:35:00.357519",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.343928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now before we go on, I will tell a story. Scientist created what I coded above. Now the model was working, hence they were at a risk of getting laid off. So they decided, \"No we will not stop. We will make more terms and turn the world upside down just like Luffy will!\". Hence they created hundred more terms. Now I amd not saying they are not useful but man who is going to remember so many formulas? Anyways I will scratch code them too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65eafa",
   "metadata": {
    "papermill": {
     "duration": 0.013525,
     "end_time": "2024-03-26T09:35:00.385012",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.371487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## False Positive Rate\n",
    "Lets begin with a simple Type I error, also referred as False Positive Rate. You rarely would use this metric alone.\n",
    "\n",
    "$FPR = \\frac{FP}{FP+TN}$\n",
    "\n",
    "## False Negative Rate\n",
    "Next is Type II error, commonly called False Negative Rate. Usually, it is not used alone but rather with some other metric.\n",
    "\n",
    "$FNR = \\frac{FN}{FN+TN}$\n",
    "\n",
    "## Specificity\n",
    "Now a good one. We have Specificity, commonly known as True Negative Rate. This is used more often. Formula for it is:\n",
    "\n",
    "$TNR = \\frac{TN}{TN+FP}$\n",
    "\n",
    "## Negative Prediction Rate\n",
    "This is one I did not know existed. Formula for it:\n",
    "\n",
    "$NPV = \\frac{TN}{TN+FN}$\n",
    "\n",
    "## False Discovery Rate\n",
    "This is also one I did not know existed. Formula for it:\n",
    "\n",
    "$TNR = \\frac{FP}{FP+TP}$\n",
    "\n",
    "## Recall\n",
    "Next up is a important one, Recall or Sensitivity also called True Positive Rate. Formula for it is:\n",
    "\n",
    "$TPR = \\frac{TP}{TP+FN}$\n",
    "\n",
    "## Precision\n",
    "Now is an important one. Positive Prediction Value or generally called Precision. Formula for it is:\n",
    "\n",
    "$PPV = \\frac{TP}{TP+FP}$\n",
    "\n",
    "## Accuracy\n",
    "And Finally we have Accuracy. Correct divided by total. Formual for it is:\n",
    "\n",
    "$ACC = \\frac{TP + TN}{TP + FP + TN +FN}$\n",
    "\n",
    "## F$_\\beta$ Score\n",
    "This is a general term where we change the value of $\\beta$ and create different values. Formula for it:\n",
    "\n",
    "$F_{\\beta} = (1+\\beta^2)\\frac{PPV*TPR}{\\beta^2*PPV + TPR}$\n",
    "\n",
    "## F1 Score\n",
    "Eh you thought it is over? No there is F1 score. It is a part of the beta score when beta is 1. F1 is basically the harmonic mean between precision and recall. Formula for it is:\n",
    "\n",
    "$F1 = 2\\frac{PPV*TPR}{PPV+TPR}$\n",
    "\n",
    "## F2 Score\n",
    "Then there is F2 score. It is a part of the beta score when beta is 2. F2 is basically the harmonic mean between precision and recall. Formula for it is:\n",
    "\n",
    "$F2 = 5\\frac{PPV*TPR}{4*PPV+TPR}$\n",
    "\n",
    "## Matthews Correlation Coefficient\n",
    "This is just like accuracy as well. It’s a correlation between predicted classes and ground truth. Formula is:\n",
    "\n",
    "$MCC = \\frac{(TP*TN)+(FP*FN)}{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d981b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.415107Z",
     "iopub.status.busy": "2024-03-26T09:35:00.414132Z",
     "iopub.status.idle": "2024-03-26T09:35:00.427188Z",
     "shell.execute_reply": "2024-03-26T09:35:00.426315Z"
    },
    "papermill": {
     "duration": 0.030569,
     "end_time": "2024-03-26T09:35:00.429566",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.398997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def falsePositiveRate(FP, TN):\n",
    "    FPR = FP/(FP+TN)\n",
    "    return FPR\n",
    "\n",
    "def falseNegativeRate(FN, TN):\n",
    "    FNR = FN/(FN+TN)\n",
    "    return FNR\n",
    "\n",
    "def trueNegativeRate(TN, FP):\n",
    "    TNR = TN/(TN+FP)\n",
    "    return TNR\n",
    "\n",
    "def negativePredictionValue(TN, FN):\n",
    "    NPV = TN/(TN+FN)\n",
    "    return NPV\n",
    "\n",
    "def falseDiscoveryRate(FP, TP):\n",
    "    FDR = FP/(FP+TP)\n",
    "    return FDR\n",
    "\n",
    "def truePositiveRate(TP, FN):\n",
    "    TPR = TP/(TP+FN)\n",
    "    return TPR\n",
    "\n",
    "def positivePredictionValue(TP, FP):\n",
    "    PPV = TP/(TP+FP)\n",
    "    return PPV\n",
    "\n",
    "def accuracy(TN, FN, TP, FP):\n",
    "    acc = (TP + TN)/(TP+FP+TN+FN)\n",
    "    return acc\n",
    "\n",
    "def FBetaScore(PPV, TPR, beta):\n",
    "    FBeta = (1 + beta**2)*PPV*TPR/((beta**2*PPV)+TPR)\n",
    "    return FBeta\n",
    "\n",
    "def F1Score(PPV, TPR):\n",
    "    F1 = FBetaScore(PPV, TPR, 1)\n",
    "    return F1\n",
    "\n",
    "def F2Score(PPV, TPR):\n",
    "    F2 = FBetaScore(PPV, TPR, 2)\n",
    "    return F2\n",
    "\n",
    "def matthewsCorrelationCoefficient(TN, FN, TP, FP):\n",
    "    MCC = ((TP*TN)+(FP*FN)) / ( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) )\n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c2bd14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.460643Z",
     "iopub.status.busy": "2024-03-26T09:35:00.459882Z",
     "iopub.status.idle": "2024-03-26T09:35:00.469663Z",
     "shell.execute_reply": "2024-03-26T09:35:00.468514Z"
    },
    "papermill": {
     "duration": 0.028594,
     "end_time": "2024-03-26T09:35:00.472469",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.443875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics(y, y_pred):\n",
    "    \n",
    "    TN, FN, TP, FP = findConfusionTerms(y, y_pred)\n",
    "    CM = findConfusionMatrix(TN, FN, TP, FP)\n",
    "    \n",
    "    FPR = falsePositiveRate(FP, TN)\n",
    "    FNR = falseNegativeRate(FN, TN)\n",
    "    TNR = trueNegativeRate(TN, FP)\n",
    "    NPV = negativePredictionValue(TN, FN)\n",
    "    FDR = falseDiscoveryRate(FP, TP)\n",
    "    TPR = truePositiveRate(TP, FN)\n",
    "    PPV = positivePredictionValue(TP, FP)\n",
    "    \n",
    "    ACC = accuracy(TN, FN, TP, FP)\n",
    "    \n",
    "    F1 = F1Score(PPV, TPR)\n",
    "    F2 = F2Score(PPV, TPR)\n",
    "    \n",
    "    MCC = matthewsCorrelationCoefficient(TN, FN, TP, FP)\n",
    "        \n",
    "    print(\"Confusion Matrix: \",CM)\n",
    "    \n",
    "    print(\"Type I Error: \", FPR)\n",
    "    print(\"Type II Error: \", FNR)\n",
    "    print(\"Specificity: \", TNR)\n",
    "    print(\"Negative Prediction Rate: \", NPV)\n",
    "    print(\"False Discovery Rate: \", FDR)\n",
    "    print(\"Recall: \", TPR)\n",
    "    print(\"Precision: \", PPV)\n",
    "    \n",
    "    print(\"Accuracy: \", ACC)\n",
    "    \n",
    "    print(\"F1 Score: \", F1)\n",
    "    print(\"F2 Score: \", F2)\n",
    "    \n",
    "    print(\"Matthews Correlation Coefficient: \", MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c51eb893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T09:35:00.502522Z",
     "iopub.status.busy": "2024-03-26T09:35:00.502074Z",
     "iopub.status.idle": "2024-03-26T09:35:00.508636Z",
     "shell.execute_reply": "2024-03-26T09:35:00.507704Z"
    },
    "papermill": {
     "duration": 0.024449,
     "end_time": "2024-03-26T09:35:00.511176",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.486727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[391, 14], [19, 376]]\n",
      "Type I Error:  0.0345679012345679\n",
      "Type II Error:  0.046341463414634146\n",
      "Specificity:  0.9654320987654321\n",
      "Negative Prediction Rate:  0.9536585365853658\n",
      "False Discovery Rate:  0.035897435897435895\n",
      "Recall:  0.9518987341772152\n",
      "Precision:  0.9641025641025641\n",
      "Accuracy:  0.95875\n",
      "F1 Score:  0.9579617834394905\n",
      "F2 Score:  0.9543147208121826\n",
      "Matthews Correlation Coefficient:  5.757700766448322e-06\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6531fef0",
   "metadata": {
    "papermill": {
     "duration": 0.014074,
     "end_time": "2024-03-26T09:35:00.539653",
     "exception": false,
     "start_time": "2024-03-26T09:35:00.525579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And that's it. This could be the simplest code from machine learning to exist ever. Merry Christmas."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 19,
     "sourceId": 420,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4530892,
     "sourceId": 7750407,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 112.617337,
   "end_time": "2024-03-26T09:35:01.177125",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-26T09:33:08.559788",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
